{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray Parallel Computing Demo\n",
    "\n",
    "This notebook demonstrates how to use Ray for parallel computing within Jupyter notebooks.\n",
    "\n",
    "## Features:\n",
    "- Parallel function execution\n",
    "- Performance benchmarking \n",
    "- Visualization of results\n",
    "- Matrix operations\n",
    "- Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../ray-jobs')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ray_notebook_utils import RayNotebookHelper, ray_parallel, ParallelComputing, demo_parallel_computing\n",
    "\n",
    "# Initialize Ray helper\n",
    "ray_helper = RayNotebookHelper()\n",
    "print(\"Ray initialized successfully!\")\n",
    "print(f\"Available CPUs: {ray_helper.is_initialized}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Parallel Function Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a computation-heavy function\n",
    "def heavy_computation(n):\n",
    "    \"\"\"Simulate heavy computation\"\"\"\n",
    "    total = 0\n",
    "    for i in range(n * 1000):\n",
    "        total += i ** 2\n",
    "    return total\n",
    "\n",
    "# Test data\n",
    "test_data = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "\n",
    "# Benchmark parallel vs sequential execution\n",
    "performance_result = ray_helper.benchmark_parallel_vs_sequential(\n",
    "    heavy_computation, \n",
    "    test_data, \n",
    "    \"Heavy Computation Benchmark\"\n",
    ")\n",
    "\n",
    "print(f\"\\nPerformance Summary:\")\n",
    "print(f\"Sequential time: {performance_result['sequential_time']:.3f}s\")\n",
    "print(f\"Parallel time: {performance_result['parallel_time']:.3f}s\")\n",
    "print(f\"Speedup: {performance_result['speedup']:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parallel Matrix Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test matrices\n",
    "print(\"Creating test matrices...\")\n",
    "matrices = [np.random.rand(200, 200) for _ in range(8)]\n",
    "\n",
    "# Test different matrix operations\n",
    "operations = ['multiply', 'add', 'eigenvals']\n",
    "\n",
    "for op in operations:\n",
    "    print(f\"\\nTesting {op} operation...\")\n",
    "    \n",
    "    # Time the operation\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    results = ray_helper.parallel_compute_matrix(matrices, op)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Completed {len(results)} {op} operations in {end_time - start_time:.3f}s\")\n",
    "    \n",
    "    if op == 'eigenvals':\n",
    "        # Visualize eigenvalues distribution\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        \n",
    "        for i, eigenvals in enumerate(results[:3]):  # Show first 3\n",
    "            plt.subplot(1, 3, i+1)\n",
    "            plt.hist(np.real(eigenvals), bins=20, alpha=0.7)\n",
    "            plt.title(f'Matrix {i+1} Eigenvalues')\n",
    "            plt.xlabel('Real Part')\n",
    "            plt.ylabel('Frequency')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parallel Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test datasets\n",
    "print(\"Creating test datasets...\")\n",
    "datasets = []\n",
    "for i in range(5):\n",
    "    df = pd.DataFrame({\n",
    "        'A': np.random.randn(1000),\n",
    "        'B': np.random.randn(1000),\n",
    "        'C': np.random.randn(1000),\n",
    "        'category': np.random.choice(['X', 'Y', 'Z'], 1000)\n",
    "    })\n",
    "    datasets.append(df)\n",
    "\n",
    "# Define data processing function\n",
    "def analyze_dataframe(df):\n",
    "    \"\"\"Perform statistical analysis on DataFrame\"\"\"\n",
    "    results = {\n",
    "        'mean': df.select_dtypes(include=[np.number]).mean().to_dict(),\n",
    "        'std': df.select_dtypes(include=[np.number]).std().to_dict(),\n",
    "        'correlation': df.select_dtypes(include=[np.number]).corr().iloc[0, 1],\n",
    "        'category_counts': df['category'].value_counts().to_dict()\n",
    "    }\n",
    "    return results\n",
    "\n",
    "# Process datasets in parallel\n",
    "print(\"Processing datasets in parallel...\")\n",
    "analysis_results = ray_helper.parallel_data_processing(datasets, analyze_dataframe)\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Mean values across datasets\n",
    "plt.subplot(1, 3, 1)\n",
    "means_A = [result['mean']['A'] for result in analysis_results]\n",
    "means_B = [result['mean']['B'] for result in analysis_results]\n",
    "means_C = [result['mean']['C'] for result in analysis_results]\n",
    "\n",
    "x = range(len(datasets))\n",
    "plt.plot(x, means_A, 'o-', label='Column A', marker='o')\n",
    "plt.plot(x, means_B, 's-', label='Column B', marker='s')\n",
    "plt.plot(x, means_C, '^-', label='Column C', marker='^')\n",
    "plt.xlabel('Dataset')\n",
    "plt.ylabel('Mean Value')\n",
    "plt.title('Mean Values Across Datasets')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Correlation values\n",
    "plt.subplot(1, 3, 2)\n",
    "correlations = [result['correlation'] for result in analysis_results]\n",
    "plt.bar(x, correlations, color='skyblue', alpha=0.7)\n",
    "plt.xlabel('Dataset')\n",
    "plt.ylabel('Correlation (A-B)')\n",
    "plt.title('A-B Correlation Across Datasets')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Category distribution for first dataset\n",
    "plt.subplot(1, 3, 3)\n",
    "categories = analysis_results[0]['category_counts']\n",
    "plt.pie(categories.values(), labels=categories.keys(), autopct='%1.1f%%')\n",
    "plt.title('Category Distribution (Dataset 1)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Processed {len(analysis_results)} datasets successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Monte Carlo Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo estimation of π using Ray\n",
    "import ray\n",
    "\n",
    "# Different sample sizes to test\n",
    "sample_sizes = [100000, 200000, 300000, 400000, 500000]\n",
    "\n",
    "print(\"Running Monte Carlo π estimation...\")\n",
    "\n",
    "# Submit all tasks in parallel\n",
    "futures = [ParallelComputing.monte_carlo_pi.remote(n) for n in sample_sizes]\n",
    "\n",
    "# Get results\n",
    "pi_estimates = ray.get(futures)\n",
    "\n",
    "# Visualize convergence\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Pi estimates\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(sample_sizes, pi_estimates, 'bo-', label='Estimated π')\n",
    "plt.axhline(y=np.pi, color='r', linestyle='--', label='True π')\n",
    "plt.xlabel('Sample Size')\n",
    "plt.ylabel('π Estimate')\n",
    "plt.title('Monte Carlo π Estimation')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Error analysis\n",
    "plt.subplot(1, 2, 2)\n",
    "errors = [abs(estimate - np.pi) for estimate in pi_estimates]\n",
    "plt.semilogy(sample_sizes, errors, 'ro-')\n",
    "plt.xlabel('Sample Size')\n",
    "plt.ylabel('Absolute Error')\n",
    "plt.title('Estimation Error vs Sample Size')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print results\n",
    "for size, estimate in zip(sample_sizes, pi_estimates):\n",
    "    error = abs(estimate - np.pi)\n",
    "    print(f\"Sample size: {size:6d}, π estimate: {estimate:.6f}, Error: {error:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Using the @ray_parallel Decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example using the decorator\n",
    "@ray_parallel(num_workers=4)\n",
    "def process_number(x, multiplier=2, offset=0):\n",
    "    \"\"\"Process a number with some computation\"\"\"\n",
    "    import time\n",
    "    time.sleep(0.1)  # Simulate some work\n",
    "    return (x * multiplier) + offset\n",
    "\n",
    "# Test data\n",
    "numbers = list(range(20))\n",
    "\n",
    "print(\"Using @ray_parallel decorator...\")\n",
    "\n",
    "# This will automatically run in parallel\n",
    "results = process_number(numbers, multiplier=3, offset=10)\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(numbers, results, 'o-', linewidth=2, markersize=6)\n",
    "plt.xlabel('Input')\n",
    "plt.ylabel('Output (3x + 10)')\n",
    "plt.title('Parallel Processing Results')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Processed {len(results)} items: {results[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive performance data\n",
    "performance_data = {\n",
    "    'execution_times': {\n",
    "        'sequential': 2.5,\n",
    "        'parallel': 0.8\n",
    "    },\n",
    "    'resource_usage': {\n",
    "        'CPU': 75,\n",
    "        'Memory': 45,\n",
    "        'Idle': 25\n",
    "    },\n",
    "    'throughput': {\n",
    "        'time': [0, 1, 2, 3, 4, 5],\n",
    "        'tasks_completed': [0, 15, 35, 60, 85, 100]\n",
    "    },\n",
    "    'error_rate': {\n",
    "        'success': 95,\n",
    "        'failed': 5\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display performance dashboard\n",
    "ray_helper.create_performance_dashboard(performance_data)\n",
    "\n",
    "print(\"Performance dashboard generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up Ray resources\n",
    "ray_helper.shutdown()\n",
    "print(\"Ray shutdown completed. Resources cleaned up.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Basic parallel execution** with performance benchmarking\n",
    "2. **Parallel matrix operations** with different algorithms\n",
    "3. **Parallel data processing** with pandas DataFrames\n",
    "4. **Monte Carlo simulation** for π estimation\n",
    "5. **Decorator-based parallel functions** for easy usage\n",
    "6. **Performance visualization** and monitoring\n",
    "\n",
    "### Key Benefits:\n",
    "- Automatic parallelization of compute-intensive tasks\n",
    "- Built-in performance monitoring and visualization\n",
    "- Easy integration with existing notebook workflows\n",
    "- Scalable from local development to cluster deployment\n",
    "\n",
    "### Next Steps:\n",
    "- Try with your own computation-heavy functions\n",
    "- Experiment with different numbers of workers\n",
    "- Scale up to larger datasets\n",
    "- Deploy on Ray clusters for even better performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}